{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6948081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용에 법적 제약이 없으며, 누구나 변경, 재배포할 수 있는 공개된 외부 데이터 사용 가능\n",
    "# 사용에 법적 제약이 없으며, 오픈소스로 공개된 사전 학습 모델(Pre-trained Model) 사용 가능\n",
    "    # 단, Hugging Face 내 sosoai가 제공하는 모든 'hansoldeco' 관련 모델 사용 불가능\n",
    "# API를 통한 외부데이터 수집, 데이터 전처리는 가능하나, API를 통한 추론은 불가능합니다. (Ex. ChatGPT API를 통한 추론 등 불가능)\n",
    "    # 반드시 언어 모델 학습의 과정이 존재해야하며, 학습된 언어 모델을 바탕으로 추론이 이루어져야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66974e73-fed7-49f5-b7cd-14406dce87c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qja19\\anaconda3\\envs\\papering\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\qja19\\anaconda3\\envs\\papering\\lib\\site-packages\\huggingface_hub\\utils\\_hf_folder.py:98: UserWarning: A token has been found in `C:\\Users\\qja19\\.huggingface\\token`. This is the old path where tokens were stored. The new location is `C:\\Users\\qja19\\.cache\\huggingface\\token` which is configurable using `HF_HOME` environment variable. Your token has been copied to this new location. You can now safely delete the old token file manually or use `huggingface-cli logout`.\n",
      "  warnings.warn(\n",
      "Downloading .gitattributes: 100%|██████████| 690/690 [00:00<?, ?B/s] \n",
      "Downloading 1_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n",
      "Downloading 2_Dense/config.json: 100%|██████████| 114/114 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.58M/1.58M [00:00<00:00, 26.2MB/s]\n",
      "Downloading README.md: 100%|██████████| 2.45k/2.45k [00:00<?, ?B/s]\n",
      "Downloading config.json: 100%|██████████| 556/556 [00:00<?, ?B/s] \n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 122/122 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 539M/539M [00:06<00:00, 82.2MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "Downloading tokenizer.json: 100%|██████████| 1.96M/1.96M [00:00<00:00, 1.99MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 452/452 [00:00<?, ?B/s] \n",
      "Downloading vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 1.26MB/s]\n",
      "Downloading modules.json: 100%|██████████| 341/341 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6193b9-4408-4d5c-b26e-e309c9474a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 예시\n",
    "preds = [\n",
    "    \"이번 경진대회는 질의 응답 처리를 수행하는 AI 모델을 개발해야합니다.\",\n",
    "    \"데이콘은 플랫폼입니다.\"\n",
    "]\n",
    "\n",
    "gts = [\n",
    "    \"이번 경진대회의 주제는 도배 하자 질의 응답 AI 모델 개발입니다.\",\n",
    "    \"데이콘은 국내 최대의 AI 경진대회 플랫폼입니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141ae52c-9625-4b9a-a6ff-e801b565d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플에 대한 Cosine Similarity 산식\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f5e898-c9ff-4a7a-b310-e762659552ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 :  이번 경진대회는 질의 응답 처리를 수행하는 AI 모델을 개발해야합니다.\n",
      "정답 :  이번 경진대회의 주제는 도배 하자 질의 응답 AI 모델 개발입니다.\n",
      "Cosine Similarity Score :  0.8344027\n",
      "--------------------\n",
      "예측 :  데이콘은 플랫폼입니다.\n",
      "정답 :  데이콘은 국내 최대의 AI 경진대회 플랫폼입니다.\n",
      "Cosine Similarity Score :  0.6281422\n",
      "--------------------\n",
      "전체 샘플의 Cosine Similarity Score 평균 :  0.73127246\n"
     ]
    }
   ],
   "source": [
    "sample_scores = []\n",
    "for pred, gt in zip(preds, gts):\n",
    "    # 생성된 답변 내용을 512 Embedding Vector로 변환\n",
    "    pred_embed = model.encode(pred)\n",
    "    gt_embed = model.encode(gt)\n",
    "    \n",
    "    sample_score = cosine_similarity(gt_embed, pred_embed)\n",
    "    # Cosine Similarity Score가 0보다 작으면 0으로 간주\n",
    "    sample_score = max(sample_score, 0)\n",
    "    print('예측 : ', pred)\n",
    "    print('정답 : ', gt)\n",
    "    print('Cosine Similarity Score : ', sample_score)\n",
    "    print('-'*20)\n",
    "    sample_scores.append(sample_score)\n",
    "print('전체 샘플의 Cosine Similarity Score 평균 : ', np.mean(sample_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25eb843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)\n",
    "\n",
    "scoring_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# MODEL = \"nlpai-lab/kullm-polyglot-5.8b-v2\"\n",
    "# MODEL = \"KT-AI/midm-bitext-S-7B-inst-v1\"\n",
    "# MODEL = \"EleutherAI/polyglot-ko-1.3b\"\n",
    "# MODEL = \"EleutherAI/polyglot-ko-1.3b_sft10\"\n",
    "MODEL = \"EleutherAI/polyglot-ko-1.3b_f-sft_5\"\n",
    "MODEL = \"model/model/further_train/checkpoint-last_f-sft_5/checkpoint-last\"\n",
    "# MODEL = \"facebook/xglm-564M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    # \"model/\" + MODEL + \"/checkpoint-last\",\n",
    "    MODEL,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device=f\"cuda\")\n",
    "model.eval()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"model/\" + MODEL + \"/checkpoint-last\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding vector 변환\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0\n",
    "\n",
    "def compute_cosine(pred, gt):\n",
    "    \n",
    "    # 생성된 답변 내용을 512 Embedding Vector로 변환\n",
    "    pred_embed = scoring_model.encode(pred)\n",
    "    gt_embed = scoring_model.encode(gt)\n",
    "    \n",
    "    sample_score = cosine_similarity(gt_embed, pred_embed)\n",
    "    # Cosine Similarity Score가 0보다 작으면 0으로 간주\n",
    "    sample_score = max(sample_score, 0)\n",
    "    print('예측 : ', pred)\n",
    "    print('정답 : ', gt)\n",
    "    print('Cosine Similarity Score : ', sample_score)\n",
    "    print('-'*20)\n",
    "\n",
    "    return sample_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# prompter = Prompter(\"kullm\")\n",
    "\n",
    "def infer(instruction=\"\", input_text=\"\"):\n",
    "    prompt = instruction + input_text\n",
    "    output = pipe(prompt, max_length=512, temperature=0.2, num_beams=5, eos_token_id=2)\n",
    "    s = output[0][\"generated_text\"].split('답변:')[-1].strip()\n",
    "    result = s\n",
    "\n",
    "    return result\n",
    "\n",
    "# f\"\"\"###질문: {example['quenstion'][i]}\n",
    "# ###범주: {example['category'][i]}\n",
    "# ###답변: {example['answer'][i]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# idx = random.randint(0, 664)\n",
    "# data = train_df.iloc[1, 1:3]\n",
    "# ans = train_df.iloc[1, 4]\n",
    "# q1, q2 = data\n",
    "# instruction = \"건축, 도배에 관한 질의응답입니다. 간단하게 대답해주세요.\"\n",
    "# instruction = ''\n",
    "# result1 = infer(instruction, \"###Q: \" + q1 + \"\\n###A: \")\n",
    "# result2 = infer(instruction, q2)\n",
    "# print(\"Q\",q1)\n",
    "# print(\"A\",result1)\n",
    "# print()\n",
    "# print(q2)\n",
    "# print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_cosine(result1, ans), compute_cosine(result2, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/preproc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:16, 16.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "2it [00:35, 17.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "3it [00:51, 17.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "4it [01:08, 16.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "5it [01:25, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "6it [01:43, 17.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "7it [01:59, 17.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "8it [02:16, 16.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "9it [02:35, 17.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "10it [02:51, 17.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "11it [03:08, 17.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "12it [03:25, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "13it [03:43, 17.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "14it [04:00, 17.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "15it [04:16, 17.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "16it [04:35, 17.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "17it [04:52, 17.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "18it [05:08, 16.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "19it [05:24, 16.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "20it [05:42, 17.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "21it [05:58, 16.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "22it [06:15, 16.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "23it [06:32, 16.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "24it [06:49, 16.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "25it [07:06, 16.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "26it [07:22, 16.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "27it [07:40, 17.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "28it [07:57, 17.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "29it [08:13, 16.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "30it [08:31, 17.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "31it [08:48, 17.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "32it [09:06, 17.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "33it [09:22, 16.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "34it [09:40, 17.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "35it [09:57, 17.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "36it [10:05, 14.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "37it [10:22, 15.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "38it [10:40, 16.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "39it [10:56, 16.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "40it [11:13, 16.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "41it [11:30, 16.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "42it [11:47, 16.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "43it [12:03, 16.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "44it [12:20, 16.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "45it [12:39, 17.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "46it [12:55, 17.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "47it [13:11, 16.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "48it [13:28, 16.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "49it [13:44, 16.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "50it [14:01, 16.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "51it [14:17, 16.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "52it [14:33, 16.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "53it [14:50, 16.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "54it [15:06, 16.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "55it [15:22, 16.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "56it [15:41, 17.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "57it [15:57, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "58it [16:14, 16.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "59it [16:32, 17.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "60it [16:48, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "61it [17:05, 16.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "62it [17:22, 16.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "63it [17:39, 16.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "64it [17:55, 16.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "65it [18:11, 16.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "66it [18:29, 16.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "67it [18:46, 16.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "68it [19:02, 16.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "69it [19:19, 16.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "70it [19:37, 17.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "71it [19:53, 16.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "72it [20:10, 16.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "73it [20:27, 16.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "74it [20:45, 17.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "75it [21:01, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "76it [21:18, 16.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "77it [21:36, 17.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "78it [21:52, 16.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "79it [22:09, 16.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "80it [22:26, 16.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "81it [22:44, 17.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "82it [23:00, 16.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "83it [23:17, 16.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "84it [23:35, 17.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "85it [23:52, 17.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "86it [24:09, 17.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "87it [24:25, 16.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "88it [24:43, 17.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "89it [25:00, 16.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "90it [25:16, 16.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "91it [25:35, 17.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "92it [25:51, 17.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "93it [26:08, 16.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "94it [26:24, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "95it [26:43, 17.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "96it [27:00, 17.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "97it [27:16, 16.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "98it [27:23, 13.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "99it [27:41, 15.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100it [27:58, 15.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "101it [28:14, 15.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "102it [28:32, 16.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "103it [28:48, 16.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "104it [29:05, 16.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "105it [29:22, 16.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "106it [29:40, 16.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "107it [29:56, 16.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "108it [30:13, 16.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "109it [30:29, 16.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "110it [30:46, 16.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "111it [31:02, 16.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "112it [31:19, 16.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "113it [31:36, 16.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "114it [31:52, 16.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "115it [32:09, 16.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "116it [32:25, 16.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "117it [32:43, 17.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "118it [33:00, 16.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "119it [33:17, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "120it [33:35, 17.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "121it [33:51, 16.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "122it [34:07, 16.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "123it [34:24, 16.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "124it [34:43, 17.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "125it [34:59, 17.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "126it [35:16, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "127it [35:34, 17.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "128it [35:50, 16.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "129it [36:07, 16.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "130it [36:23, 16.80s/it]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "for i, text in tqdm(enumerate(test_df['question'])):\n",
    "    # pred = infer(text).split('.')[0]\n",
    "    pred = infer(\"###질문: \" + text + \"\\n###답변:\")\n",
    "    pred = scoring_model.encode(pred)\n",
    "    submission.iloc[i, 1:] = pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vec_0</th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "      <th>vec_4</th>\n",
       "      <th>vec_5</th>\n",
       "      <th>vec_6</th>\n",
       "      <th>vec_7</th>\n",
       "      <th>vec_8</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_502</th>\n",
       "      <th>vec_503</th>\n",
       "      <th>vec_504</th>\n",
       "      <th>vec_505</th>\n",
       "      <th>vec_506</th>\n",
       "      <th>vec_507</th>\n",
       "      <th>vec_508</th>\n",
       "      <th>vec_509</th>\n",
       "      <th>vec_510</th>\n",
       "      <th>vec_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.035210</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.066983</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>-0.044902</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018339</td>\n",
       "      <td>-0.039620</td>\n",
       "      <td>-0.029461</td>\n",
       "      <td>-0.032569</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.006292</td>\n",
       "      <td>0.024488</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.050308</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>-0.006316</td>\n",
       "      <td>0.043964</td>\n",
       "      <td>-0.012013</td>\n",
       "      <td>-0.000516</td>\n",
       "      <td>0.072565</td>\n",
       "      <td>-0.021178</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>-0.040333</td>\n",
       "      <td>0.030803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022531</td>\n",
       "      <td>-0.015690</td>\n",
       "      <td>0.026113</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>-0.036512</td>\n",
       "      <td>0.043442</td>\n",
       "      <td>-0.025938</td>\n",
       "      <td>0.027305</td>\n",
       "      <td>-0.021794</td>\n",
       "      <td>0.034515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>-0.008436</td>\n",
       "      <td>-0.011499</td>\n",
       "      <td>-0.042170</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.105926</td>\n",
       "      <td>-0.049753</td>\n",
       "      <td>-0.051349</td>\n",
       "      <td>-0.045694</td>\n",
       "      <td>0.056298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032728</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.064047</td>\n",
       "      <td>-0.040778</td>\n",
       "      <td>0.012211</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>-0.041107</td>\n",
       "      <td>-0.023482</td>\n",
       "      <td>-0.049628</td>\n",
       "      <td>0.069997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>-0.010799</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>0.057094</td>\n",
       "      <td>-0.059067</td>\n",
       "      <td>-0.060367</td>\n",
       "      <td>-0.007579</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033620</td>\n",
       "      <td>-0.024804</td>\n",
       "      <td>0.029809</td>\n",
       "      <td>-0.051397</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>-0.054066</td>\n",
       "      <td>-0.049180</td>\n",
       "      <td>-0.034041</td>\n",
       "      <td>0.061599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>-0.023186</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>-0.015720</td>\n",
       "      <td>-0.013581</td>\n",
       "      <td>0.098607</td>\n",
       "      <td>-0.019275</td>\n",
       "      <td>0.078659</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>-0.018426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.061035</td>\n",
       "      <td>0.040050</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>-0.039191</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.022402</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.039522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>TEST_125</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>-0.042760</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>-0.007113</td>\n",
       "      <td>0.077466</td>\n",
       "      <td>0.030668</td>\n",
       "      <td>0.021609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014816</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.040374</td>\n",
       "      <td>-0.047482</td>\n",
       "      <td>0.042004</td>\n",
       "      <td>0.028202</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>0.013112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>TEST_126</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.047265</td>\n",
       "      <td>-0.036992</td>\n",
       "      <td>-0.006113</td>\n",
       "      <td>0.080631</td>\n",
       "      <td>-0.038806</td>\n",
       "      <td>0.035686</td>\n",
       "      <td>0.025429</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>0.057414</td>\n",
       "      <td>-0.018425</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>-0.011002</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.084766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>TEST_127</td>\n",
       "      <td>-0.023581</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>-0.024375</td>\n",
       "      <td>0.053496</td>\n",
       "      <td>0.097232</td>\n",
       "      <td>-0.008287</td>\n",
       "      <td>-0.009340</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>-0.032130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034932</td>\n",
       "      <td>-0.121293</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>-0.008162</td>\n",
       "      <td>-0.038281</td>\n",
       "      <td>0.039590</td>\n",
       "      <td>0.046264</td>\n",
       "      <td>-0.011574</td>\n",
       "      <td>0.013584</td>\n",
       "      <td>-0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>TEST_128</td>\n",
       "      <td>0.039401</td>\n",
       "      <td>-0.013772</td>\n",
       "      <td>-0.066872</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.107638</td>\n",
       "      <td>-0.065605</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>-0.007505</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035605</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.013389</td>\n",
       "      <td>-0.029797</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>-0.004484</td>\n",
       "      <td>-0.021936</td>\n",
       "      <td>0.032521</td>\n",
       "      <td>-0.005766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>TEST_129</td>\n",
       "      <td>0.042097</td>\n",
       "      <td>-0.014113</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>-0.012619</td>\n",
       "      <td>0.105685</td>\n",
       "      <td>-0.023722</td>\n",
       "      <td>0.037003</td>\n",
       "      <td>0.040620</td>\n",
       "      <td>0.090688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030119</td>\n",
       "      <td>-0.014622</td>\n",
       "      <td>-0.053108</td>\n",
       "      <td>-0.016444</td>\n",
       "      <td>0.023396</td>\n",
       "      <td>0.032687</td>\n",
       "      <td>-0.093325</td>\n",
       "      <td>0.070343</td>\n",
       "      <td>-0.033392</td>\n",
       "      <td>0.002843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     vec_0     vec_1     vec_2     vec_3     vec_4     vec_5  \\\n",
       "0    TEST_000  0.002573  0.035210  0.012646  0.005216  0.066983  0.025870   \n",
       "1    TEST_001 -0.006316  0.043964 -0.012013 -0.000516  0.072565 -0.021178   \n",
       "2    TEST_002 -0.008436 -0.011499 -0.042170  0.001840  0.105926 -0.049753   \n",
       "3    TEST_003 -0.010799  0.012507  0.015290  0.030082  0.057094 -0.059067   \n",
       "4    TEST_004 -0.023186 -0.017924 -0.015720 -0.013581  0.098607 -0.019275   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "125  TEST_125  0.009847 -0.042760  0.009235  0.009850  0.108200 -0.007113   \n",
       "126  TEST_126  0.017769 -0.047265 -0.036992 -0.006113  0.080631 -0.038806   \n",
       "127  TEST_127 -0.023581  0.004912 -0.024375  0.053496  0.097232 -0.008287   \n",
       "128  TEST_128  0.039401 -0.013772 -0.066872  0.013240  0.107638 -0.065605   \n",
       "129  TEST_129  0.042097 -0.014113  0.006783 -0.012619  0.105685 -0.023722   \n",
       "\n",
       "        vec_6     vec_7     vec_8  ...   vec_502   vec_503   vec_504  \\\n",
       "0   -0.044902  0.007480  0.008723  ... -0.018339 -0.039620 -0.029461   \n",
       "1    0.022248 -0.040333  0.030803  ... -0.022531 -0.015690  0.026113   \n",
       "2   -0.051349 -0.045694  0.056298  ... -0.032728  0.002324  0.064047   \n",
       "3   -0.060367 -0.007579  0.000650  ... -0.033620 -0.024804  0.029809   \n",
       "4    0.078659  0.005730 -0.018426  ... -0.016727 -0.061035  0.040050   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "125  0.077466  0.030668  0.021609  ...  0.014816  0.016811  0.040374   \n",
       "126  0.035686  0.025429  0.013350  ... -0.025982 -0.020841  0.057414   \n",
       "127 -0.009340  0.026250 -0.032130  ... -0.034932 -0.121293  0.017691   \n",
       "128  0.010459 -0.007505  0.013110  ... -0.035605  0.001200  0.013389   \n",
       "129  0.037003  0.040620  0.090688  ... -0.030119 -0.014622 -0.053108   \n",
       "\n",
       "      vec_505   vec_506   vec_507   vec_508   vec_509   vec_510   vec_511  \n",
       "0   -0.032569  0.000073 -0.006292  0.024488  0.006801  0.050308  0.039636  \n",
       "1   -0.031141 -0.036512  0.043442 -0.025938  0.027305 -0.021794  0.034515  \n",
       "2   -0.040778  0.012211  0.008556 -0.041107 -0.023482 -0.049628  0.069997  \n",
       "3   -0.051397  0.005900  0.005190 -0.054066 -0.049180 -0.034041  0.061599  \n",
       "4    0.007069 -0.039191  0.021982  0.036501  0.022402  0.000076  0.039522  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "125 -0.047482  0.042004  0.028202  0.018279 -0.037097 -0.032359  0.013112  \n",
       "126 -0.018425  0.010714  0.012469  0.004307 -0.011002  0.004503  0.084766  \n",
       "127 -0.008162 -0.038281  0.039590  0.046264 -0.011574  0.013584 -0.000163  \n",
       "128 -0.029797 -0.007267  0.010359 -0.004484 -0.021936  0.032521 -0.005766  \n",
       "129 -0.016444  0.023396  0.032687 -0.093325  0.070343 -0.033392  0.002843  \n",
       "\n",
       "[130 rows x 513 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv(f\"data/submission/polyglot-ko-1.3b_f-sft_5.csv\", index=False)\n",
    "pd.read_csv(f\"data/submission/polyglot-ko-1.3b_f-sft_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv(f\"data/submission/{MODEL.split('/')[-1]}.csv\", index=False)\n",
    "# pd.read_csv(f\"data/submission/{MODEL.split('/')[-1]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kwon\\anaconda3\\envs\\papering\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "modules.json: 100%|██████████| 341/341 [00:00<00:00, 341kB/s]\n",
      "c:\\Users\\kwon\\anaconda3\\envs\\papering\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kwon\\.cache\\huggingface\\hub\\models--sentence-transformers--distiluse-base-multilingual-cased-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "config_sentence_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 121kB/s]\n",
      "README.md: 100%|██████████| 2.47k/2.47k [00:00<?, ?B/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 52.8kB/s]\n",
      "config.json: 100%|██████████| 556/556 [00:00<?, ?B/s] \n",
      "pytorch_model.bin: 100%|██████████| 539M/539M [00:46<00:00, 11.6MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 452/452 [00:00<00:00, 452kB/s]\n",
      "vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 1.25MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.96M/1.96M [00:01<00:00, 1.95MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n",
      "2_Dense/config.json: 100%|██████████| 114/114 [00:00<?, ?B/s] \n",
      "pytorch_model.bin: 100%|██████████| 1.58M/1.58M [00:00<00:00, 10.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)\n",
    "\n",
    "scoring_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# MODEL = \"nlpai-lab/kullm-polyglot-5.8b-v2\"\n",
    "# MODEL = \"KT-AI/midm-bitext-S-7B-inst-v1\"\n",
    "# MODEL = \"EleutherAI/polyglot-ko-1.3b\"\n",
    "MODEL = \"EleutherAI/polyglot-ko-1.3b_sft10\"\n",
    "MODEL=r\"\\maywell\\Synatra-42dot-1.3B_sft10\"\n",
    "# MODEL = \"facebook/xglm-564M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"model/\" + MODEL + \"/checkpoint-last\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device=f\"cuda\")\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/\" + MODEL + \"/checkpoint-last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding vector 변환\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0\n",
    "\n",
    "def compute_cosine(pred, gt):\n",
    "    \n",
    "    # 생성된 답변 내용을 512 Embedding Vector로 변환\n",
    "    pred_embed = scoring_model.encode(pred)\n",
    "    gt_embed = scoring_model.encode(gt)\n",
    "    \n",
    "    sample_score = cosine_similarity(gt_embed, pred_embed)\n",
    "    # Cosine Similarity Score가 0보다 작으면 0으로 간주\n",
    "    sample_score = max(sample_score, 0)\n",
    "    print('예측 : ', pred)\n",
    "    print('정답 : ', gt)\n",
    "    print('Cosine Similarity Score : ', sample_score)\n",
    "    print('-'*20)\n",
    "\n",
    "    return sample_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# prompter = Prompter(\"kullm\")\n",
    "\n",
    "def infer(instruction=\"\", input_text=\"\"):\n",
    "    prompt = instruction + input_text\n",
    "    output = pipe(prompt, max_length=512, temperature=0.2, num_beams=5, eos_token_id=2)\n",
    "    s = output[0][\"generated_text\"].split('A: ')[-1]\n",
    "    result = s\n",
    "\n",
    "    return result\n",
    "\n",
    "# f\"\"\"###질문: {example['quenstion'][i]}\n",
    "# ###범주: {example['category'][i]}\n",
    "# ###답변: {example['answer'][i]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 내진설계의 종류 좀 알려줘\n",
      "A  내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 내진설계의 종류는 지역의 지진 환경 및 건물의 특성에 맞게 선택되며, 안전하고 견고한 건물을 만드는 데 중요한 역할을 합니다. 따라서 각 지역의 지진 환경을 고려하여 적합한 내진설계의 종류를 선택하는 것이 중요합니다.  내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 내진설계의 종류는 지역의 지진 환경 및 건물의 특성에 맞게 선택되며, 안전하고 견고한 건물을 만드는 데 중요한 역할을 합니다. 따라서 각 지역의 지진 환경을 고려하여 적합한 내진설계의 종류를 선택하는 것이 중요합니다.  내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 내진설계의 종류는 지역의 지진 환경 및 건물의 특성에 맞게 선택되며, 안전하고 견고한 건물을 만드는 데 중요한 역할을 합니다. 따라서 각 지역의 지진 환경을 고려하여 적합한 내진설계의 종류를 선택하는 것이 중요합니다.  내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 내진설\n",
      "\n",
      "내진설계에는 어떤 종류가 있는지 자세히 알려주실 수 있나요?\n",
      "건축, 도배에 관한 질의응답입니다. 간단하게 대답해주세요.내진설계에는 어떤 종류가 있는지 자세히 알려주실 수 있나요? 내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 질의응답은 건축물의 내구성과 안전성을 높이는 데 도움이 됩니다. 감사합니다.내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 답변은 건축물의 내구성과 안전성을 높이는 데 도움이 됩니다. 감사합니다.내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 답변은 건축물의 내구성과 안전성을 높이는 데 도움이 됩니다. 감사합니다.내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 답변은 건축물의 내구성과 안전성을 높이는 데 도움이 됩니다. 감사합니다.내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 답변은 건축물의 내구\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, 664)\n",
    "data = train_df.iloc[1, 1:3]\n",
    "ans = train_df.iloc[1, 4]\n",
    "q1, q2 = data\n",
    "instruction = \"건축, 도배에 관한 질의응답입니다. 간단하게 대답해주세요.\"\n",
    "result1 = infer(instruction, \"###Q: \" + q1 + \"\\n###A: \")\n",
    "result2 = infer(instruction, q2)\n",
    "print(\"Q\",q1)\n",
    "print(\"A\",result1)\n",
    "print()\n",
    "print(q2)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 :   내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 내진설계의 종류는 지역의 지진 환경 및 건물의 특성에 맞게 선택되며, 안전하고 견고한 건물을 만드는 데 중요한 역할을 합니다. 따라서 각 지역의 지진 환경을 고려하여 적합한 내진설계의 종류를 선택하는 것이 중요합니다.  내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 내진설계의 종류는 지역의 지진 환경 및 건물의 특성에 맞게 선택되며, 안전하고 견고한 건물을 만드는 데 중요한 역할을 합니다. 따라서 각 지역의 지진 환경을 고려하여 적합한 내진설계의 종류를 선택하는 것이 중요합니다.  내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 내진설계의 종류는 지역의 지진 환경 및 건물의 특성에 맞게 선택되며, 안전하고 견고한 건물을 만드는 데 중요한 역할을 합니다. 따라서 각 지역의 지진 환경을 고려하여 적합한 내진설계의 종류를 선택하는 것이 중요합니다.  내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 내진설\n",
      "정답 :  내진 설계의 종류로 내진구조, 제진구조, 면진구조가 있습니다.\n",
      "Cosine Similarity Score :  0.43291423\n",
      "--------------------\n",
      "예측 :  건축, 도배에 관한 질의응답입니다. 간단하게 대답해주세요.내진설계에는 어떤 종류가 있는지 자세히 알려주실 수 있나요? 내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 질의응답은 건축물의 내구성과 안전성을 높이는 데 도움이 됩니다. 감사합니다.내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 답변은 건축물의 내구성과 안전성을 높이는 데 도움이 됩니다. 감사합니다.내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 답변은 건축물의 내구성과 안전성을 높이는 데 도움이 됩니다. 감사합니다.내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 답변은 건축물의 내구성과 안전성을 높이는 데 도움이 됩니다. 감사합니다.내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조물 전체에 지진으로부터의 영향을 분산시키기 위해 설계되었습니다. 반면, 제진구조는 지진으로 인한 충격을 줄이기 위해 주로 건물의 지지대에 설치됩니다. 또한 면진구조는 건물의 외벽에서 지진으로부터 보호받기 위한 설계 방식입니다. 이러한 답변은 건축물의 내구\n",
      "정답 :  내진 설계의 종류로 내진구조, 제진구조, 면진구조가 있습니다.\n",
      "Cosine Similarity Score :  0.40721378\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43291423, 0.40721378)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cosine(result1, ans), compute_cosine(result2, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/preproc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130it [32:50, 15.16s/it]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "for i, text in tqdm(enumerate(test_df['question'])):\n",
    "    # pred = infer(text).split('.')[0]\n",
    "    pred = infer(instruction, text)\n",
    "    pred = scoring_model.encode(pred)\n",
    "    submission.iloc[i, 1:] = pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='Synatra-42dot-1.3B_sft10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vec_0</th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "      <th>vec_4</th>\n",
       "      <th>vec_5</th>\n",
       "      <th>vec_6</th>\n",
       "      <th>vec_7</th>\n",
       "      <th>vec_8</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_502</th>\n",
       "      <th>vec_503</th>\n",
       "      <th>vec_504</th>\n",
       "      <th>vec_505</th>\n",
       "      <th>vec_506</th>\n",
       "      <th>vec_507</th>\n",
       "      <th>vec_508</th>\n",
       "      <th>vec_509</th>\n",
       "      <th>vec_510</th>\n",
       "      <th>vec_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0.050423</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>-0.004277</td>\n",
       "      <td>-0.012403</td>\n",
       "      <td>0.034989</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005100</td>\n",
       "      <td>-0.037386</td>\n",
       "      <td>0.042823</td>\n",
       "      <td>-0.028536</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>-0.025020</td>\n",
       "      <td>0.075805</td>\n",
       "      <td>0.030236</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.052760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0.020735</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>-0.014682</td>\n",
       "      <td>-0.011415</td>\n",
       "      <td>-0.024977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>-0.000495</td>\n",
       "      <td>0.042313</td>\n",
       "      <td>-0.020366</td>\n",
       "      <td>-0.040632</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>0.047930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0.031516</td>\n",
       "      <td>-0.059725</td>\n",
       "      <td>-0.055009</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.067844</td>\n",
       "      <td>-0.021349</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008242</td>\n",
       "      <td>-0.012243</td>\n",
       "      <td>0.067022</td>\n",
       "      <td>-0.021126</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>-0.003010</td>\n",
       "      <td>-0.028776</td>\n",
       "      <td>0.082253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>-0.006158</td>\n",
       "      <td>-0.031964</td>\n",
       "      <td>0.028383</td>\n",
       "      <td>0.041894</td>\n",
       "      <td>-0.033372</td>\n",
       "      <td>-0.022815</td>\n",
       "      <td>-0.021335</td>\n",
       "      <td>-0.039976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003490</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.047875</td>\n",
       "      <td>-0.047296</td>\n",
       "      <td>-0.012026</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>-0.013087</td>\n",
       "      <td>-0.011817</td>\n",
       "      <td>-0.011446</td>\n",
       "      <td>0.062047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0.032581</td>\n",
       "      <td>0.012349</td>\n",
       "      <td>-0.004242</td>\n",
       "      <td>-0.011176</td>\n",
       "      <td>0.062909</td>\n",
       "      <td>0.023073</td>\n",
       "      <td>0.042893</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>-0.021611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028276</td>\n",
       "      <td>0.013586</td>\n",
       "      <td>0.050220</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>-0.032319</td>\n",
       "      <td>-0.004558</td>\n",
       "      <td>0.026456</td>\n",
       "      <td>0.040374</td>\n",
       "      <td>-0.003893</td>\n",
       "      <td>0.067779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>TEST_125</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>-0.029987</td>\n",
       "      <td>-0.005501</td>\n",
       "      <td>-0.006226</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>-0.049835</td>\n",
       "      <td>0.049427</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.022671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>-0.002894</td>\n",
       "      <td>0.094166</td>\n",
       "      <td>-0.034169</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>-0.012093</td>\n",
       "      <td>0.045191</td>\n",
       "      <td>-0.015211</td>\n",
       "      <td>-0.026634</td>\n",
       "      <td>0.053393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>TEST_126</td>\n",
       "      <td>0.053792</td>\n",
       "      <td>-0.048998</td>\n",
       "      <td>-0.045557</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.074532</td>\n",
       "      <td>-0.002417</td>\n",
       "      <td>0.017463</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>-0.019457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013017</td>\n",
       "      <td>-0.025400</td>\n",
       "      <td>0.048935</td>\n",
       "      <td>-0.016889</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>0.015076</td>\n",
       "      <td>-0.006445</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.078474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>TEST_127</td>\n",
       "      <td>-0.008898</td>\n",
       "      <td>0.012549</td>\n",
       "      <td>-0.032952</td>\n",
       "      <td>0.034074</td>\n",
       "      <td>0.066123</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>-0.008536</td>\n",
       "      <td>-0.068177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.057616</td>\n",
       "      <td>0.049681</td>\n",
       "      <td>-0.015763</td>\n",
       "      <td>-0.027778</td>\n",
       "      <td>0.029018</td>\n",
       "      <td>0.048885</td>\n",
       "      <td>0.027484</td>\n",
       "      <td>-0.025435</td>\n",
       "      <td>0.049164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>TEST_128</td>\n",
       "      <td>0.024318</td>\n",
       "      <td>-0.009040</td>\n",
       "      <td>-0.075605</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>0.070618</td>\n",
       "      <td>-0.043342</td>\n",
       "      <td>0.028830</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038633</td>\n",
       "      <td>-0.007672</td>\n",
       "      <td>0.034521</td>\n",
       "      <td>-0.023638</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>-0.015758</td>\n",
       "      <td>0.006341</td>\n",
       "      <td>0.026481</td>\n",
       "      <td>0.040047</td>\n",
       "      <td>0.036294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>TEST_129</td>\n",
       "      <td>0.057124</td>\n",
       "      <td>-0.022162</td>\n",
       "      <td>-0.018434</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.059027</td>\n",
       "      <td>-0.014031</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.046126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.029717</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>-0.047557</td>\n",
       "      <td>0.054952</td>\n",
       "      <td>-0.038584</td>\n",
       "      <td>0.049408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     vec_0     vec_1     vec_2     vec_3     vec_4     vec_5  \\\n",
       "0    TEST_000  0.050423  0.021929 -0.004277 -0.012403  0.034989  0.003718   \n",
       "1    TEST_001  0.020735  0.013235  0.006741  0.013161  0.050746  0.002894   \n",
       "2    TEST_002  0.031516 -0.059725 -0.055009  0.004024  0.067844 -0.021349   \n",
       "3    TEST_003  0.011521 -0.006158 -0.031964  0.028383  0.041894 -0.033372   \n",
       "4    TEST_004  0.032581  0.012349 -0.004242 -0.011176  0.062909  0.023073   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "125  TEST_125  0.041787 -0.029987 -0.005501 -0.006226  0.057556 -0.049835   \n",
       "126  TEST_126  0.053792 -0.048998 -0.045557  0.003684  0.074532 -0.002417   \n",
       "127  TEST_127 -0.008898  0.012549 -0.032952  0.034074  0.066123  0.002786   \n",
       "128  TEST_128  0.024318 -0.009040 -0.075605  0.035001  0.070618 -0.043342   \n",
       "129  TEST_129  0.057124 -0.022162 -0.018434  0.009552  0.059027 -0.014031   \n",
       "\n",
       "        vec_6     vec_7     vec_8  ...   vec_502   vec_503   vec_504  \\\n",
       "0   -0.001094  0.003133 -0.000515  ... -0.005100 -0.037386  0.042823   \n",
       "1   -0.014682 -0.011415 -0.024977  ...  0.010186 -0.000495  0.042313   \n",
       "2    0.010299 -0.018998  0.007556  ... -0.008242 -0.012243  0.067022   \n",
       "3   -0.022815 -0.021335 -0.039976  ... -0.003490  0.005153  0.047875   \n",
       "4    0.042893  0.016032 -0.021611  ...  0.028276  0.013586  0.050220   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "125  0.049427  0.030020  0.022671  ...  0.030844 -0.002894  0.094166   \n",
       "126  0.017463 -0.015500 -0.019457  ... -0.013017 -0.025400  0.048935   \n",
       "127  0.005002 -0.008536 -0.068177  ...  0.000075 -0.057616  0.049681   \n",
       "128  0.028830  0.012641  0.001391  ... -0.038633 -0.007672  0.034521   \n",
       "129  0.017494  0.024562  0.046126  ... -0.001442 -0.000371 -0.029717   \n",
       "\n",
       "      vec_505   vec_506   vec_507   vec_508   vec_509   vec_510   vec_511  \n",
       "0   -0.028536  0.004168 -0.025020  0.075805  0.030236  0.010631  0.052760  \n",
       "1   -0.020366 -0.040632  0.023600  0.016050  0.003394  0.023869  0.047930  \n",
       "2   -0.021126  0.014659  0.001954  0.001254 -0.003010 -0.028776  0.082253  \n",
       "3   -0.047296 -0.012026  0.006479 -0.013087 -0.011817 -0.011446  0.062047  \n",
       "4    0.010649 -0.032319 -0.004558  0.026456  0.040374 -0.003893  0.067779  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "125 -0.034169  0.006344 -0.012093  0.045191 -0.015211 -0.026634  0.053393  \n",
       "126 -0.016889  0.013491  0.017465  0.015076 -0.006445  0.003929  0.078474  \n",
       "127 -0.015763 -0.027778  0.029018  0.048885  0.027484 -0.025435  0.049164  \n",
       "128 -0.023638  0.003973 -0.015758  0.006341  0.026481  0.040047  0.036294  \n",
       "129  0.000289  0.008883  0.020806 -0.047557  0.054952 -0.038584  0.049408  \n",
       "\n",
       "[130 rows x 513 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv(f\"data/submission/{MODEL.split('/')[-1]}.csv\", index=False)\n",
    "pd.read_csv(f\"data/submission/{MODEL.split('/')[-1]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
